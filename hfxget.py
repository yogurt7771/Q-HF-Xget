#!/usr/bin/env python3
"""
Xget Hugging Face ä¸‹è½½åŠ é€Ÿå™¨
ç”¨äºæ›¿ä»£ hf download å‘½ä»¤ï¼Œé€šè¿‡ Xget åŠ é€Ÿä¸‹è½½ï¼Œé¿å…ç½‘ç»œé—®é¢˜

ç­–ç•¥ï¼š
1. ä½¿ç”¨ HF API è·å–å®Œæ•´æ–‡ä»¶åˆ—è¡¨
2. å°æ–‡ä»¶ä» hf-mirror.com ä¸‹è½½
3. LFS æ–‡ä»¶ä» Xget ä¸‹è½½
4. éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
"""

import argparse
import re
import shutil
import signal
import subprocess
import sys
import threading
import time
import traceback
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from pathlib import Path

try:
    import requests
    import urllib3

    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

from huggingface_hub import HfApi
from huggingface_hub.file_download import hf_hub_url
from huggingface_hub.utils import build_hf_headers

try:
    from huggingface_hub._local_folder import \
        read_download_metadata as hf_read_download_metadata
    from huggingface_hub._local_folder import \
        write_download_metadata as hf_write_download_metadata
except ImportError:
    hf_write_download_metadata = None
    hf_read_download_metadata = None
from tqdm import tqdm

# å…¨å±€å˜é‡ç”¨äºè·Ÿè¸ªä¸­æ–­çŠ¶æ€
interrupted = False

# åº”ç”¨å…ƒä¿¡æ¯
APP_NAME = "hfxget"
APP_VERSION = "1.0"

# ç»Ÿä¸€ç®¡ç† aria2 tqdm çš„æ˜¾ç¤ºä½ç½®ï¼Œé¿å…å¤šçº¿ç¨‹å†²çª
_aria2_position_lock = threading.Lock()
_aria2_active_positions = set()


def _aria2_acquire_position():
    with _aria2_position_lock:
        pos = 1
        while pos in _aria2_active_positions:
            pos += 1
        _aria2_active_positions.add(pos)
        return pos


def _aria2_release_position(position):
    with _aria2_position_lock:
        _aria2_active_positions.discard(position)


_UNIT_MULTIPLIERS = {
    "B": 1,
    "KiB": 1024,
    "MiB": 1024 ** 2,
    "GiB": 1024 ** 3,
    "TiB": 1024 ** 4,
}


def _unit_to_bytes(value, unit):
    multiplier = _UNIT_MULTIPLIERS.get(unit, 1)
    return int(float(value) * multiplier)


def build_default_hf_headers(additional=None):
    base_headers = {
        "Accept": "*/*",
        "Accept-Language": "en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
    }
    if additional:
        base_headers.update(additional)

    return build_hf_headers(
        token=False,
        library_name=APP_NAME,
        library_version=APP_VERSION,
        headers=base_headers,
    )


def signal_handler(signum, frame):
    """å¤„ç†Ctrl+Cä¸­æ–­ä¿¡å·"""
    global interrupted
    interrupted = True
    print("\n\nâš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å· (Ctrl+C)ï¼Œæ­£åœ¨åœæ­¢ä¸‹è½½...")
    print("è¯·ç­‰å¾…å½“å‰ä¸‹è½½ä»»åŠ¡å®Œæˆ...")


# æ³¨å†Œä¿¡å·å¤„ç†å™¨
signal.signal(signal.SIGINT, signal_handler)


@dataclass
class DownloadResult:
    success: bool
    status_code: int | None = None
    message: str | None = None


class DownloaderInterface(ABC):
    """ä¸‹è½½å™¨æŠ½è±¡æ¥å£"""

    @abstractmethod
    def download_file(self, url: str, local_path: str, resume: bool = True) -> DownloadResult:
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        pass

    @abstractmethod
    def get_name(self):
        """è·å–ä¸‹è½½å™¨åç§°"""
        pass


class RequestsDownloader(DownloaderInterface):
    """åŸºäº requests åº“çš„ä¸‹è½½å™¨"""

    def __init__(self):
        self.default_headers = build_default_hf_headers()

    def get_name(self):
        return "requests"

    def download_file(self, url, local_path, resume=True):
        """ä½¿ç”¨ requests ä¸‹è½½æ–‡ä»¶"""
        if not REQUESTS_AVAILABLE:
            raise ImportError("requests åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install requests")

        local_path = Path(local_path)
        local_path.parent.mkdir(parents=True, exist_ok=True)

        if not resume:
            temp_path = local_path
            if local_path.exists():
                print(f"â™»ï¸  è¦†ç›–ç°æœ‰æ–‡ä»¶: {local_path.name}")
        else:
            temp_path = local_path.with_suffix(local_path.suffix + ".incomplete")
            if local_path.exists():
                print(f"âœ… å·²å­˜åœ¨ä¸”è·³è¿‡: {local_path.name}")
                return DownloadResult(success=True)

        session = requests.Session()
        session.headers.update(self.default_headers)

        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

        headers = session.headers.copy()
        mode = "wb"
        initial_pos = 0

        if resume and temp_path.exists() and temp_path != local_path:
            initial_pos = temp_path.stat().st_size
            headers["Range"] = f"bytes={initial_pos}-"
            mode = "ab"
            print(
                f"æ–­ç‚¹ç»­ä¼ : {local_path.name} (ä» {initial_pos / (1024*1024):.1f} MB å¼€å§‹)"
            )

        try:
            response = session.get(
                url,
                headers=headers,
                stream=True,
                timeout=(30, 60),
                verify=True,
                allow_redirects=True,
            )

            if response.status_code == 416 and resume:
                if temp_path.exists() and temp_path != local_path:
                    temp_path.rename(local_path)
                    print(f"âœ… æœ¬åœ°å·²å®Œæ•´ï¼Œé‡å‘½å: {local_path.name}")
                    return DownloadResult(success=True)
                return DownloadResult(success=True)

            response.raise_for_status()
            total_size = int(response.headers.get("content-length", 0)) + initial_pos

            with open(temp_path, mode) as f:
                with tqdm(
                    desc=local_path.name,
                    total=total_size,
                    initial=initial_pos,
                    unit="B",
                    unit_scale=True,
                    unit_divisor=1024,
                    leave=False,
                    bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]",
                ) as pbar:
                    for chunk in response.iter_content(chunk_size=65536):
                        if interrupted:
                            print(f"\nâ¹ï¸  ä¸‹è½½è¢«ä¸­æ–­: {local_path.name}")
                            return DownloadResult(success=False, message="interrupted")
                        if chunk:
                            f.write(chunk)
                            pbar.update(len(chunk))

            if resume and temp_path != local_path:
                temp_path.rename(local_path)

            return DownloadResult(success=True)

        except Exception as e:
            if (
                hasattr(e, 'response')
                and e.response is not None
                and e.response.status_code in [401, 403, 404]
            ):
                print(f"ğŸš« HTTP {e.response.status_code}: {local_path.name}")
                if resume and temp_path.exists() and temp_path != local_path:
                    try:
                        temp_path.unlink()
                    except OSError:
                        pass
                return DownloadResult(success=False, status_code=e.response.status_code, message=str(e))
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {local_path.name}")
            print(f"åŸå› : {str(e)}")
            if resume and temp_path.exists() and temp_path != local_path:
                try:
                    temp_path.unlink()
                except OSError:
                    pass
            return DownloadResult(success=False, message=str(e))


class Aria2Downloader(DownloaderInterface):
    """åŸºäº aria2c çš„ä¸‹è½½å™¨"""

    def __init__(self):
        self.aria2_path = shutil.which("aria2c")

        if not self.aria2_path and sys.platform == "win32":
            local_candidate = Path(__file__).with_name("aria2c.exe")
            if local_candidate.exists():
                self.aria2_path = str(local_candidate)

        if not self.aria2_path and sys.platform != "win32":
            local_candidate = Path(__file__).with_name("aria2c")
            if local_candidate.exists():
                self.aria2_path = str(local_candidate)

        if not self.aria2_path:
            raise EnvironmentError("æœªæ£€æµ‹åˆ° aria2cï¼Œè¯·å…ˆå®‰è£… aria2 ä¸‹è½½å™¨")

        self.progress_pattern = re.compile(
            r"\[#\S+\s+([\d\.]+)([KMGTP]?i?B)/([\d\.]+)([KMGTP]?i?B)\((\d+)%\)\s+CN:(\d+)\s+DL:([\d\.]+)([KMGTP]?i?B)\s+ETA:([^\]]+)\]"
        )
        self.http_error_pattern = re.compile(r"status=(\d{3})")
        self.default_headers = build_default_hf_headers()

    def get_name(self):
        return "aria2"

    def download_file(self, url, local_path, resume=True):
        local_path = Path(local_path)
        local_path.parent.mkdir(parents=True, exist_ok=True)

        control_file = Path(str(local_path) + ".aria2")
        fresh_download = not resume or (local_path.exists() and not control_file.exists())

        if fresh_download and local_path.exists():
            tqdm.write(f"â™»ï¸  è¦†ç›–ç°æœ‰æ–‡ä»¶: {local_path.name}")
            try:
                local_path.unlink()
            except OSError as exc:
                tqdm.write(f"âš ï¸  æ— æ³•åˆ é™¤æ—§æ–‡ä»¶ {local_path.name}: {exc}")
                return DownloadResult(success=False, message=str(exc))

        if fresh_download and control_file.exists():
            try:
                control_file.unlink()
            except OSError:
                pass

        aria_args = [
            self.aria2_path,
            "--continue=true",
            "--auto-file-renaming=false",
            "--summary-interval=1",
            "--console-log-level=notice",
            "--show-console-readout=true",
            "--download-result=hide",
            "--max-tries=5",
            "--retry-wait=10",
            "--max-connection-per-server=8",
            "--min-split-size=1M",
            "--enable-mmap=true",
            "--disk-cache=64M",
            "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            f"--dir={local_path.parent}",
            f"--out={local_path.name}",
        ]

        aria_args.append(
            "--allow-overwrite=true" if fresh_download else "--allow-overwrite=false"
        )

        for header_key, header_value in self.default_headers.items():
            aria_args.append(f"--header={header_key}: {header_value}")

        aria_args.append(url)

        position = _aria2_acquire_position()
        progress_bar = tqdm(
            total=1,
            desc=local_path.name,
            unit="B",
            unit_scale=True,
            unit_divisor=1024,
            leave=False,
            position=position,
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]",
        )
        progress_total = None

        http_status_code = None
        last_error_message = None

        try:
            process = subprocess.Popen(
                aria_args,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
            )

            if process.stdout is not None:
                for raw_line in iter(process.stdout.readline, ""):
                    if interrupted:
                        process.terminate()
                        break
                    line = raw_line.strip()
                    if not line:
                        continue

                    match = self.progress_pattern.search(line)
                    if match:
                        current = _unit_to_bytes(match.group(1), match.group(2))
                        total = _unit_to_bytes(match.group(3), match.group(4))
                        connections = match.group(6)
                        speed_value = match.group(7)
                        speed_unit = match.group(8)
                        eta = match.group(9)

                        if progress_total != total and total > 0:
                            progress_total = total
                            progress_bar.total = total
                        delta = current - progress_bar.n
                        if delta < 0:
                            progress_bar.n = current
                            progress_bar.refresh()
                        elif delta:
                            progress_bar.update(delta)
                        progress_bar.set_postfix_str(
                            f"CN:{connections} DL:{speed_value}{speed_unit} ETA:{eta.strip()}"
                        )
                        progress_bar.refresh()
                        continue

                    if line.startswith("FILE:"):
                        progress_bar.set_description(f"{local_path.name}")
                        continue

                    status_match = self.http_error_pattern.search(line)
                    if status_match:
                        http_status_code = int(status_match.group(1))

                    last_error_message = line
                    tqdm.write(f"aria2[{local_path.name}] âœ {line}")
                process.stdout.close()

            return_code = process.wait()

            if return_code == 0 and not interrupted:
                return DownloadResult(success=True)

            if interrupted:
                tqdm.write(f"â¹ï¸  æ‰‹åŠ¨ä¸­æ–­ aria2 è¿›ç¨‹: {local_path.name}")
                return DownloadResult(success=False, message="interrupted")

            tqdm.write(f"âŒ aria2 ä¸‹è½½å¤±è´¥: {local_path.name} (é€€å‡ºç  {return_code})")
            return DownloadResult(success=False, status_code=http_status_code, message=last_error_message)

        except FileNotFoundError:
            tqdm.write("âŒ æœªæ‰¾åˆ° aria2c å¯æ‰§è¡Œæ–‡ä»¶ï¼Œè¯·ç¡®è®¤å·²å®‰è£…å¹¶åœ¨ PATH ä¸­")
            return DownloadResult(success=False, message="aria2c not found")
        except Exception as exc:
            tqdm.write(f"âŒ aria2 ä¸‹è½½å¼‚å¸¸: {local_path.name} | {exc}")
            return DownloadResult(success=False, message=str(exc))
        finally:
            progress_bar.close()
            _aria2_release_position(position)


class XgetHFDownloader:
    def __init__(
        self,
        xget_base_url="https://xget.xi-xu.me/hf",
        hf_mirror_url="https://hf-mirror.com",
        downloader_type="requests",
    ):
        self.xget_base_url = xget_base_url
        self.hf_mirror_url = hf_mirror_url
        self.hf_api = HfApi(endpoint=hf_mirror_url)

        # LFS æ–‡ä»¶å¤§å°é˜ˆå€¼ (50MB)
        self.lfs_size_threshold = 50 * 1024 * 1024

        # ç¼“å­˜å½“å‰è§£æåˆ°çš„æäº¤å“ˆå¸Œï¼Œä¾›å†™å…¥å…ƒæ•°æ®ä½¿ç”¨
        self.resolved_commit_hash = None

        # é€‰æ‹©ä¸‹è½½å™¨
        self.downloader: DownloaderInterface = None
        if downloader_type == "requests":
            self.downloader = RequestsDownloader()
        elif downloader_type == "aria2":
            self.downloader = Aria2Downloader()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¸‹è½½å™¨ç±»å‹: {downloader_type}")

        print(f"ğŸ› ï¸  ä¸‹è½½æ ¸å¿ƒ: {self.downloader.get_name()}")
        print(f"ğŸª  HF é•œåƒ: {self.hf_mirror_url}")
        print(f"ğŸš€  Xget åŠ é€Ÿ: {self.xget_base_url}")

    def get_repo_file_list(self, repo_id, repo_type="model", revision="main"):
        """è·å–ä»“åº“æ–‡ä»¶åˆ—è¡¨å’Œè¯¦ç»†ä¿¡æ¯"""
        try:
            print(
                f"ğŸ“¡ è·å–æ–‡ä»¶åˆ—è¡¨: {repo_type} {repo_id} @ {revision}"
            )

            repo_info = self.hf_api.repo_info(
                repo_id, repo_type=repo_type, revision=revision, files_metadata=True
            )

            self.resolved_commit_hash = (
                getattr(repo_info, "sha", None)
                or getattr(repo_info, "commit", None)
                or getattr(repo_info, "commit_hash", None)
            )

            files_info = []
            for sibling in repo_info.siblings:
                file_info = {
                    "filename": sibling.rfilename,
                    "size": sibling.size,
                    "lfs": sibling.lfs,
                    "blob_id": sibling.blob_id,
                }
                files_info.append(file_info)

            return files_info

        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯401é”™è¯¯ï¼Œå¦‚æœæ˜¯åˆ™ä¸é‡è¯•
            if (
                hasattr(e, "response")
                and e.response is not None
                and e.response.status_code == 401
            ):
                print(f"ğŸš« è®¿é—®å—é™ (401): {repo_id} | {e}")
                return []
            print(f"âŒ è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def is_lfs_file(self, file_info):
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸º LFS æ–‡ä»¶"""
        if file_info.get("size", 0) < self.lfs_size_threshold:
            return False

        return bool(file_info.get("lfs"))

    def build_download_url(
        self, repo_id, filename, repo_type="model", revision="main", is_lfs=False
    ):
        """æ„å»ºä¸‹è½½ URL"""
        # ç¡®ä¿æ–‡ä»¶ååœ¨URLä¸­ä½¿ç”¨æ­£æ–œæ 
        url_filename = filename.replace("\\", "/")

        if is_lfs:
            # LFS æ–‡ä»¶ä½¿ç”¨ Xget
            if repo_type == "dataset":
                hf_url = f"https://huggingface.co/datasets/{repo_id}/resolve/{revision}/{url_filename}?download=true"
            elif repo_type == "space":
                hf_url = f"https://huggingface.co/spaces/{repo_id}/resolve/{revision}/{url_filename}?download=true"
            else:  # model
                hf_url = f"https://huggingface.co/{repo_id}/resolve/{revision}/{url_filename}?download=true"

            download_url = hf_url.replace("https://huggingface.co", self.xget_base_url)
            url_type = "Xget"
        else:
            # æ™®é€šæ–‡ä»¶ä½¿ç”¨ hf-mirror
            # download_url = None
            download_url = hf_hub_url(
                repo_id,
                filename,
                repo_type=repo_type,
                revision=revision,
                endpoint=self.hf_mirror_url,
            )
            url_type = "hf-mirror"

        hf_mirror_param = {
            "repo_id": repo_id,
            "filename": filename,
            "revision": revision,
            "repo_type": repo_type,
        }

        return download_url, url_type, hf_mirror_param

    def _extract_file_etag(self, file_info):
        """ä»æ–‡ä»¶ä¿¡æ¯ä¸­è§£ææœŸæœ›çš„ ETagã€‚"""

        lfs_info = file_info.get("lfs")
        if lfs_info is not None:
            sha256 = getattr(lfs_info, "sha256", None)
            if sha256 is None and isinstance(lfs_info, dict):
                sha256 = lfs_info.get("sha256")
            if sha256:
                return sha256

            oid = getattr(lfs_info, "oid", None)
            if oid is None and isinstance(lfs_info, dict):
                oid = lfs_info.get("oid")
            if isinstance(oid, str) and oid.startswith("sha256:"):
                return oid.split(":", 1)[1]
            return oid

        return file_info.get("blob_id")

    def verify_file_integrity(self, local_dir, file_path, file_info):
        """é€šè¿‡å…ƒæ•°æ®éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ã€‚"""

        if not file_path.exists():
            return False

        expected_size = file_info.get("size")
        if expected_size is not None:
            actual_size = file_path.stat().st_size
            if actual_size != expected_size:
                print(
                    f"âŒ æ–‡ä»¶å¤§å°ä¸åŒ¹é…: {file_path.name} | æœŸæœ› {expected_size}, å®é™… {actual_size}"
                )
                return False

        metadata = None
        filename = file_info.get("filename")
        if filename and hf_read_download_metadata is not None:
            try:
                metadata = hf_read_download_metadata(Path(local_dir), filename)
            except Exception as e:
                print(f"âš ï¸  è¯»å–å…ƒæ•°æ®å¤±è´¥ {file_path.name}: {e}")

        if metadata is None:
            self._write_local_metadata(local_dir, file_info)
            if filename and hf_read_download_metadata is not None:
                try:
                    metadata = hf_read_download_metadata(Path(local_dir), filename)
                except Exception as e:
                    print(f"âš ï¸  è¯»å–å…ƒæ•°æ®å¤±è´¥ {file_path.name}: {e}")

        if metadata is None:
            print(f"âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆå…ƒæ•°æ® {file_path.name}")
            return False

        expected_etag = self._extract_file_etag(file_info)
        if expected_etag and metadata.etag != expected_etag:
            print(
                f"âŒ ETag ä¸åŒ¹é…: {file_path.name} | æœŸæœ› {expected_etag}, å®é™… {metadata.etag}"
            )
            return False

        if (
            self.resolved_commit_hash
            and metadata.commit_hash
            and metadata.commit_hash != self.resolved_commit_hash
        ):
            print(
                f"âŒ æäº¤å“ˆå¸Œä¸åŒ¹é…: {file_path.name} | å½“å‰ {self.resolved_commit_hash}, å…ƒæ•°æ® {metadata.commit_hash}"
            )
            return False

        return True

    def _write_local_metadata(self, local_dir, file_info):
        """å°†ä¸‹è½½çš„æ–‡ä»¶å…ƒæ•°æ®å†™å…¥æœ¬åœ°ç¼“å­˜ç›®å½•ã€‚"""

        if hf_write_download_metadata is None:
            return

        if not self.resolved_commit_hash:
            return

        etag = self._extract_file_etag(file_info)

        if not etag:
            return

        filename = file_info.get("filename")
        if not filename:
            return

        try:
            hf_write_download_metadata(
                Path(local_dir), filename, self.resolved_commit_hash, etag
            )
        except Exception as e:
            print(f"âš ï¸  å†™å…¥å…ƒæ•°æ®å¤±è´¥ {file_info['filename']}: {e}")

    def download_and_verify_file(
        self,
        url: str,
        local_dir: Path,
        local_path: Path,
        file_info,
        url_type,
        hf_mirror_param,
        max_attempts=5,
    ):
        """ä¸‹è½½æ–‡ä»¶å¹¶éªŒè¯å®Œæ•´æ€§"""

        attempt = 0

        download_success = False
        performed_download = False
        while True:
            if interrupted:
                print(f"â¹ï¸  ä¸‹è½½è¢«ä¸­æ–­ï¼Œè·³è¿‡: {local_path.name}")
                return {"success": False, "downloaded": False, "url_type": url_type}

            if self.verify_file_integrity(local_dir, local_path, file_info):
                print(f"âœ… å·²å­˜åœ¨ä¸”é€šè¿‡æ ¡éªŒ: {local_path.name}")
                return {
                    "success": True,
                    "downloaded": performed_download,
                    "url_type": url_type,
                }

            attempt += 1
            attempt_note = f"{attempt}/{max_attempts}æ¬¡å°è¯•"
            print(
                f"ğŸ“¥ å¼€å§‹ä¸‹è½½: {local_path.name} | æ¥æº: {url_type} | {attempt_note}"
            )
            final_source = url_type

            if url_type in ["Xget", "HfMirror"]:
                try:
                    download_result = self.downloader.download_file(
                        url, local_path, resume=True
                    )
                    performed_download = True

                    if download_result.success:
                        download_success = True
                    else:
                        status_code = download_result.status_code
                        if status_code in {401, 403, 404}:
                            print(f"ğŸ”€ Xget ä¸‹è½½é”™è¯¯ï¼š{status_code=}, å°è¯•åˆ‡æ¢ hf-mirror: {local_path.name}")
                            local_path.unlink(missing_ok=True)
                            control_file = Path(str(local_path) + ".aria2")
                            control_file.unlink(missing_ok=True)
                            url_type = "hf-mirror"
                        else:
                            message = download_result.message
                            if message:
                                print(f"âš ï¸ Xget ä¸‹è½½æœªå®Œæˆ: {local_path.name} | {message}")
                            else:
                                print(f"âš ï¸ Xget ä¸‹è½½æœªå®Œæˆ: {local_path.name}")
                except Exception as e:
                    performed_download = True
                    print(f"âŒ Xget ä¸‹è½½å¼‚å¸¸: {local_path.name} | {e}")
                    print(traceback.format_exc())
            elif url_type in ["hf-mirror"]:
                try:
                    self.hf_api.hf_hub_download(**hf_mirror_param, local_dir=local_dir, resume_download=True)
                    download_success = True
                    performed_download = True
                except Exception as e:
                    performed_download = True
                    if hasattr(e, "response") and e.response is not None and e.response.status_code in [401, 403, 404]:
                        print(f"ğŸš« HF é•œåƒè®¿é—®å—é™ ({e.response.status_code}): {local_path.name} | {e}")
                        return {
                            "success": False,
                            "downloaded": performed_download,
                            "url_type": url_type,
                        }
                    print(f"âŒ é•œåƒä¸‹è½½å¼‚å¸¸: {local_path.name} | {e}")
            else:
                print(f"âŒ æœªçŸ¥ä¸‹è½½ç±»å‹: {url_type} | {local_path.name}")
                return {"success": False, "downloaded": False, "url_type": url_type}

            if not download_success:
                if attempt < max_attempts:
                    wait_seconds = 2
                    print(f"ğŸ” å‡†å¤‡é‡è¯•: {local_path.name} | ä¸‹ä¸€æ¬¡å°è¯• {attempt + 1}/{max_attempts} | ç­‰å¾… {wait_seconds}s")
                    time.sleep(wait_seconds)
                    continue
                print(f"ğŸš« æ”¾å¼ƒä¸‹è½½: {local_path.name} | å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
                return {"success": False, "downloaded": performed_download, "url_type": final_source}

            if download_success:
                if local_path.exists():
                    size_mb = local_path.stat().st_size / (1024 * 1024)
                    print(f"âœ… ä¸‹è½½ç»“æŸ: {local_path.name} | {size_mb:.3f} MB")
                else:
                    print(f"âœ… ä¸‹è½½ç»“æŸ: {local_path.name}")

    def download_repo(
        self,
        repo_id,
        local_dir,
        repo_type="model",
        revision="main",
        max_workers=4,
        include_patterns=None,
        exclude_patterns=None,
    ):
        """ä¸‹è½½æ•´ä¸ªä»“åº“"""
        # éªŒè¯ä»“åº“ID
        try:
            self.hf_api.repo_info(repo_id, repo_type=repo_type, revision=revision)
        except Exception as e:
            print(f"âŒ ä»“åº“ä¿¡æ¯æ— æ•ˆ: {e}")
            return False

        local_dir = Path(local_dir)
        local_dir.mkdir(parents=True, exist_ok=True)

        # è·å–æ–‡ä»¶åˆ—è¡¨
        files_info = self.get_repo_file_list(repo_id, repo_type, revision)

        if not files_info:
            print("âŒ æœªæ‰¾åˆ°æ–‡ä»¶æˆ–æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨")
            return False

        # è¿‡æ»¤æ–‡ä»¶
        if include_patterns:
            files_info = [
                f
                for f in files_info
                if any(pattern in f["filename"] for pattern in include_patterns)
            ]

        if exclude_patterns:
            files_info = [
                f
                for f in files_info
                if not any(pattern in f["filename"] for pattern in exclude_patterns)
            ]

        # åˆ†ç±»æ–‡ä»¶
        lfs_files = []
        regular_files = []

        for file_info in files_info:
            if self.is_lfs_file(file_info):
                lfs_files.append(file_info)
            else:
                regular_files.append(file_info)

        total_files = len(files_info)
        print(
            f"ğŸ“‚ æ–‡ä»¶ç»Ÿè®¡: å…± {total_files} ä¸ª | LFS (Xget): {len(lfs_files)} | æ™®é€š (hf-mirror): {len(regular_files)}"
        )

        files_to_download = []

        for file_info in files_info:
            filename = file_info["filename"]
            local_path = local_dir / filename
            is_lfs = self.is_lfs_file(file_info)

            url, url_type, hf_mirror_param = self.build_download_url(
                repo_id, filename, repo_type, revision, is_lfs
            )
            source_icon = "ğŸ”—" if url_type == "Xget" else "ğŸª"
            print(f"{source_icon} æ’é˜Ÿ: {filename}")
            files_to_download.append(
                (url, local_path, file_info, url_type, hf_mirror_param)
            )

        print(f"\nğŸ§¾ ä»»åŠ¡æ€»æ•°: {len(files_to_download)}")

        if not files_to_download:
            print("âœ… æ‰€æœ‰æ–‡ä»¶å‡å·²é€šè¿‡æ ¡éªŒï¼Œæ— éœ€ä¸‹è½½")
            return True

        print("ğŸš€ å¯åŠ¨ä¸‹è½½ä»»åŠ¡")

        # å¹¶å‘ä¸‹è½½æ–‡ä»¶
        successful_downloads = 0
        failed_downloads = 0
        total_bytes_downloaded = 0
        start_time = time.time()
        xget_downloads = 0
        mirror_downloads = 0
        verified_without_downloads = 0

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_task = {
                executor.submit(
                    self.download_and_verify_file,
                    url,
                    local_dir,
                    local_path,
                    file_info,
                    url_type,
                    hf_mirror_param,
                ): (url, local_path, file_info, url_type, hf_mirror_param)
                for url, local_path, file_info, url_type, hf_mirror_param in files_to_download
            }

            with tqdm(
                total=len(files_to_download),
                desc="æ–‡ä»¶ä¸‹è½½è¿›åº¦",
                unit="æ–‡ä»¶",
                position=0,
            ) as main_pbar:
                for future in as_completed(future_to_task):
                    # æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
                    if interrupted:
                        print(f"\nâš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å–æ¶ˆå‰©ä½™ä¸‹è½½ä»»åŠ¡...")
                        # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                        for f in future_to_task:
                            f.cancel()
                        break

                    try:
                        url, local_path, file_info, url_type, hf_mirror_param = future_to_task[future]
                        result = future.result()
                        if isinstance(result, dict):
                            if result.get("success"):
                                successful_downloads += 1
                                if result.get("downloaded"):
                                    if result.get("url_type") == "Xget":
                                        xget_downloads += 1
                                    else:
                                        mirror_downloads += 1
                                    if local_path.exists():
                                        total_bytes_downloaded += local_path.stat().st_size
                                else:
                                    verified_without_downloads += 1
                            else:
                                failed_downloads += 1
                                print(f"âŒ ä»»åŠ¡å¤±è´¥: {file_info['filename']}")
                        elif result:
                            successful_downloads += 1
                            if url_type == "Xget":
                                xget_downloads += 1
                            else:
                                mirror_downloads += 1
                            if local_path.exists():
                                total_bytes_downloaded += local_path.stat().st_size
                        else:
                            failed_downloads += 1
                            print(f"âŒ ä»»åŠ¡å¤±è´¥: {file_info['filename']}")
                    except Exception as e:
                        print(f"ğŸ’¥ ä»»åŠ¡å¼‚å¸¸: {local_path.name} | {e}")
                        failed_downloads += 1
                    finally:
                        main_pbar.update(1)

                        elapsed_time = time.time() - start_time
                        if elapsed_time > 0:
                            avg_speed = total_bytes_downloaded / elapsed_time
                            main_pbar.set_postfix(
                                {
                                    "æˆåŠŸ": successful_downloads,
                                    "å¤±è´¥": failed_downloads,
                                    "å·²éªŒè¯": verified_without_downloads,
                                    "å¹³å‡é€Ÿåº¦": f"{avg_speed / (1024*1024):.1f} MB/s",
                                }
                            )

        end_time = time.time()
        total_time = end_time - start_time
        avg_speed = total_bytes_downloaded / total_time if total_time > 0 else 0

        print(f"\nğŸ“Š ä¸‹è½½ç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸ: {successful_downloads}")
        print(f"    ğŸ”„ å·²å­˜åœ¨éªŒè¯: {verified_without_downloads}")
        print(f"    ğŸ”— Xgetä¸‹è½½: {xget_downloads}")
        print(f"    ğŸª é•œåƒä¸‹è½½: {mirror_downloads}")
        print(f"  âŒ å¤±è´¥: {failed_downloads}")
        print(f"  ğŸ“ æ€»è®¡: {len(files_to_download)}")
        print(f"  ğŸ’¾ ä¸‹è½½é‡: {total_bytes_downloaded / (1024*1024*1024):.2f} GB")
        print(f"  â±ï¸  ç”¨æ—¶: {total_time:.1f} ç§’")
        print(f"  ğŸš€ å¹³å‡é€Ÿåº¦: {avg_speed / (1024*1024):.1f} MB/s")
        print(f"  ğŸ”§ ä¸‹è½½æ ¸å¿ƒ: {self.downloader.get_name()}")

        return failed_downloads == 0


def main():
    parser = argparse.ArgumentParser(
        description="Xget Hugging Face ä¸‹è½½åŠ é€Ÿå™¨ï¼ˆæ— Gitä¾èµ–ç‰ˆæœ¬ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python xget_hf.py download microsoft/DialoGPT-medium --local-dir ./model
  python xget_hf.py download squad --repo-type dataset --local-dir ./data
  python xget_hf.py download microsoft/DialoGPT-medium --max-workers 8 --downloader requests
  python xget_hf.py download bigscience/bloom --downloader aria2

ä¸‹è½½ç­–ç•¥:
  1. ä½¿ç”¨ HF API è·å–å®Œæ•´æ–‡ä»¶åˆ—è¡¨å’Œä¿¡æ¯
  2. å°æ–‡ä»¶ä» hf-mirror.com å¿«é€Ÿä¸‹è½½
  3. LFS å¤§æ–‡ä»¶ä» Xget åŠ é€Ÿä¸‹è½½
  4. éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ï¼ˆæ–‡ä»¶å¤§å°éªŒè¯ï¼‰
        """,
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    download_parser = subparsers.add_parser("download", help="ä¸‹è½½æ¨¡å‹/æ•°æ®é›†/ç©ºé—´")
    download_parser.add_argument("repo_id", help="ä»“åº“IDï¼Œæ ¼å¼: username/repo-name")
    download_parser.add_argument("--local-dir", required=True, help="æœ¬åœ°ç›®å½•è·¯å¾„")
    download_parser.add_argument(
        "--repo-type",
        choices=["model", "dataset", "space"],
        default="model",
        help="ä»“åº“ç±»å‹ (é»˜è®¤: model)",
    )
    download_parser.add_argument(
        "--revision", default="main", help="åˆ†æ”¯/æ ‡ç­¾/æäº¤ (é»˜è®¤: main)"
    )
    download_parser.add_argument(
        "--max-workers", type=int, default=4, help="å¹¶å‘ä¸‹è½½æ•° (é»˜è®¤: 4)"
    )
    download_parser.add_argument("--include", nargs="*", help="åŒ…å«çš„æ–‡ä»¶æ¨¡å¼")
    download_parser.add_argument("--exclude", nargs="*", help="æ’é™¤çš„æ–‡ä»¶æ¨¡å¼")
    download_parser.add_argument(
        "--hf-mirror-url",
        default="https://hf-mirror.com",
        help="HF é•œåƒURLï¼Œç”¨äºæ™®é€šæ–‡ä»¶ (é»˜è®¤: https://hf-mirror.com)",
    )
    download_parser.add_argument(
        "--xget-url",
        default="https://xget.xi-xu.me/hf",
        help="Xget åŸºç¡€URLï¼Œç”¨äº LFS æ–‡ä»¶ (é»˜è®¤: https://xget.xi-xu.me/hf)",
    )
    download_parser.add_argument(
        "--downloader",
        choices=["requests", "aria2"],
        default="requests",
        help="ä¸‹è½½æ ¸å¿ƒ",
    )

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    if args.command == "download":
        # æ£€æŸ¥ä¸‹è½½å™¨å¯ç”¨æ€§
        if args.downloader == "requests" and not REQUESTS_AVAILABLE:
            print("âŒ requests åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install requests")
            return 1

        try:
            downloader = XgetHFDownloader(
                args.xget_url, args.hf_mirror_url, args.downloader
            )
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–ä¸‹è½½å™¨å¤±è´¥: {e}")
            return 1

        success = downloader.download_repo(
            repo_id=args.repo_id,
            local_dir=args.local_dir,
            repo_type=args.repo_type,
            revision=args.revision,
            max_workers=args.max_workers,
            include_patterns=args.include,
            exclude_patterns=args.exclude,
        )

        # æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
        if interrupted:
            print(f"\nâš ï¸  ä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­ (Ctrl+C)")
            print("å·²ä¸‹è½½çš„æ–‡ä»¶å°†ä¿ç•™åœ¨æœ¬åœ°ç›®å½•ä¸­")
            return 130  # æ ‡å‡†çš„ä¸­æ–­é€€å‡ºç 

        return 0 if success else 1

    return 1


if __name__ == "__main__":
    sys.exit(main())
