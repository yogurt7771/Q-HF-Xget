#!/usr/bin/env python3
"""
Xget Hugging Face ä¸‹è½½åŠ é€Ÿå™¨
ç”¨äºæ›¿ä»£ hf download å‘½ä»¤ï¼Œé€šè¿‡ Xget åŠ é€Ÿä¸‹è½½ï¼Œé¿å…ç½‘ç»œé—®é¢˜

ç­–ç•¥ï¼š
1. ä½¿ç”¨ HF API è·å–å®Œæ•´æ–‡ä»¶åˆ—è¡¨
2. å°æ–‡ä»¶ä» hf-mirror.com ä¸‹è½½
3. LFS æ–‡ä»¶ä» Xget ä¸‹è½½
4. éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
"""

import argparse
import atexit
import re
import secrets
import shutil
import signal
import socket
import subprocess
import sys
import threading
import time
import traceback
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from pathlib import Path
import requests
import urllib3

try:
    import aria2p

    ARIA2P_AVAILABLE = True
except ImportError:
    aria2p = None
    ARIA2P_AVAILABLE = False

from huggingface_hub import HfApi
from huggingface_hub._local_folder import (
    read_download_metadata as hf_read_download_metadata,
)
from huggingface_hub._local_folder import (
    write_download_metadata as hf_write_download_metadata,
)
from huggingface_hub.file_download import hf_hub_url
from huggingface_hub.utils import build_hf_headers
from huggingface_hub.utils.sha import git_hash, sha_fileobj
from tqdm import tqdm

# å…¨å±€å˜é‡ç”¨äºè·Ÿè¸ªä¸­æ–­çŠ¶æ€
interrupted = False

# åº”ç”¨å…ƒä¿¡æ¯
APP_NAME = "hfxget"
APP_VERSION = "1.0"

# ç»Ÿä¸€ç®¡ç† aria2 tqdm çš„æ˜¾ç¤ºä½ç½®ï¼Œé¿å…å¤šçº¿ç¨‹å†²çª
_aria2_position_lock = threading.Lock()
_aria2_active_positions = set()


def _aria2_acquire_position():
    with _aria2_position_lock:
        pos = 1
        while pos in _aria2_active_positions:
            pos += 1
        _aria2_active_positions.add(pos)
        return pos


def _aria2_release_position(position):
    with _aria2_position_lock:
        _aria2_active_positions.discard(position)


def build_default_hf_headers(additional=None):
    base_headers = {
        "Accept": "*/*",
        "Accept-Language": "en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
    }
    if additional:
        base_headers.update(additional)

    return build_hf_headers(
        token=False,
        library_name=APP_NAME,
        library_version=APP_VERSION,
        headers=base_headers,
    )


def signal_handler(signum, frame):
    """å¤„ç†Ctrl+Cä¸­æ–­ä¿¡å·"""
    global interrupted
    interrupted = True
    print("\n\nâš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å· (Ctrl+C)ï¼Œæ­£åœ¨åœæ­¢ä¸‹è½½...")
    print("è¯·ç­‰å¾…å½“å‰ä¸‹è½½ä»»åŠ¡å®Œæˆ...")


# æ³¨å†Œä¿¡å·å¤„ç†å™¨
signal.signal(signal.SIGINT, signal_handler)


@dataclass
class DownloadResult:
    success: bool
    status_code: int | None = None
    message: str | None = None


class DownloaderInterface(ABC):
    """ä¸‹è½½å™¨æŠ½è±¡æ¥å£"""

    @abstractmethod
    def download_file(
        self, url: str, local_path: str, resume: bool = True
    ) -> DownloadResult:
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        pass

    @abstractmethod
    def get_name(self):
        """è·å–ä¸‹è½½å™¨åç§°"""
        pass


class RequestsDownloader(DownloaderInterface):
    """åŸºäº requests åº“çš„ä¸‹è½½å™¨"""

    def __init__(self):
        self.default_headers = build_default_hf_headers()

    def get_name(self):
        return "requests"

    def download_file(self, url, local_path, resume=True):
        """ä½¿ç”¨ requests ä¸‹è½½æ–‡ä»¶"""
        local_path = Path(local_path)
        local_path.parent.mkdir(parents=True, exist_ok=True)

        if not resume:
            temp_path = local_path
            if local_path.exists():
                print(f"â™»ï¸  è¦†ç›–ç°æœ‰æ–‡ä»¶: {local_path.name}")
        else:
            temp_path = local_path.with_suffix(local_path.suffix + ".incomplete")

        session = requests.Session()
        session.headers.update(self.default_headers)

        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

        headers = session.headers.copy()
        mode = "wb"
        initial_pos = 0

        if resume and temp_path.exists() and temp_path != local_path:
            initial_pos = temp_path.stat().st_size
            headers["Range"] = f"bytes={initial_pos}-"
            mode = "ab"
            print(
                f"æ–­ç‚¹ç»­ä¼ : {local_path.name} (ä» {initial_pos / (1024*1024):.1f} MB å¼€å§‹)"
            )

        try:
            response = session.get(
                url,
                headers=headers,
                stream=True,
                timeout=(30, 60),
                verify=True,
                allow_redirects=True,
            )

            if response.status_code == 416:
                if temp_path.exists() and temp_path != local_path:
                    local_path.unlink(missing_ok=True)
                    temp_path.rename(local_path)
                    print(f"âœ… æœ¬åœ°å·²å®Œæ•´ï¼Œé‡å‘½å: {local_path.name}")
                    return DownloadResult(success=True)
                return DownloadResult(success=True)

            response.raise_for_status()
            total_size = int(response.headers.get("content-length", 0)) + initial_pos

            with open(temp_path, mode) as f:
                with tqdm(
                    desc=local_path.name,
                    total=total_size,
                    initial=initial_pos,
                    unit="B",
                    unit_scale=True,
                    unit_divisor=1024,
                    leave=False,
                    bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]",
                ) as pbar:
                    for chunk in response.iter_content(chunk_size=65536):
                        if interrupted:
                            print(f"\nâ¹ï¸  ä¸‹è½½è¢«ä¸­æ–­: {local_path.name}")
                            return DownloadResult(success=False, message="interrupted")
                        if chunk:
                            f.write(chunk)
                            pbar.update(len(chunk))

            if temp_path != local_path:
                local_path.unlink(missing_ok=True)
                temp_path.rename(local_path)

            return DownloadResult(success=True)

        except Exception as e:
            if (
                hasattr(e, "response")
                and e.response is not None
                and e.response.status_code in [401, 403, 404]
            ):
                print(f"ğŸš« HTTP {e.response.status_code}: {local_path.name}")
                temp_path.unlink(missing_ok=True)
                return DownloadResult(
                    success=False, status_code=e.response.status_code, message=str(e)
                )
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {local_path.name}")
            print(f"åŸå› : {str(e)}")
            return DownloadResult(success=False, message=str(e))


class Aria2Downloader(DownloaderInterface):
    """åŸºäº aria2p æ§åˆ¶ aria2 RPC çš„ä¸‹è½½å™¨"""

    def __init__(self):
        if not ARIA2P_AVAILABLE:
            raise EnvironmentError("aria2p æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install aria2p")

        self.aria2_path = shutil.which("aria2c")

        if not self.aria2_path and sys.platform == "win32":
            local_candidate = Path(__file__).with_name("aria2c.exe")
            if local_candidate.exists():
                self.aria2_path = str(local_candidate)

        if not self.aria2_path and sys.platform != "win32":
            local_candidate = Path(__file__).with_name("aria2c")
            if local_candidate.exists():
                self.aria2_path = str(local_candidate)

        if not self.aria2_path:
            raise EnvironmentError("æœªæ£€æµ‹åˆ° aria2cï¼Œè¯·å…ˆå®‰è£… aria2 ä¸‹è½½å™¨")

        self.http_error_pattern = re.compile(
            r"status(?:\\scode)?[:=]\s*(\\d{3})", re.IGNORECASE
        )
        self.default_headers = build_default_hf_headers()

        self.rpc_secret = secrets.token_hex(16)
        self.rpc_port = self._find_free_port()
        self._aria2_process = self._start_daemon()

        self._client = aria2p.Client(
            host="http://127.0.0.1", port=self.rpc_port, secret=self.rpc_secret
        )
        self._api = aria2p.API(self._client)
        self._api_lock = threading.Lock()
        self._ensure_daemon_ready()
        atexit.register(self.shutdown)

    def get_name(self):
        return "aria2"

    @staticmethod
    def _format_speed(speed):
        if not speed or speed <= 0:
            return "0B/s"
        units = ["B/s", "KiB/s", "MiB/s", "GiB/s", "TiB/s"]
        value = float(speed)
        for unit in units:
            if value < 1024 or unit == units[-1]:
                return f"{value:.1f}{unit}"
            value /= 1024
        return f"{value:.1f}PiB/s"

    @staticmethod
    def _format_eta(total, completed, speed):
        if not speed or speed <= 0:
            return "--"
        remaining = max(total - completed, 0)
        seconds = int(remaining / speed) if speed else 0
        if seconds < 0:
            seconds = 0
        try:
            return tqdm.format_interval(seconds)
        except AttributeError:
            from tqdm.utils import format_interval

            return format_interval(seconds)

    def _parse_http_status(self, message):
        if not message:
            return None
        match = self.http_error_pattern.search(message)
        if match:
            return int(match.group(1))
        return None

    def _find_free_port(self):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            sock.bind(("127.0.0.1", 0))
            return sock.getsockname()[1]

    def _start_daemon(self):
        args = [
            self.aria2_path,
            "--enable-rpc=true",
            "--rpc-listen-all=false",
            f"--rpc-listen-port={self.rpc_port}",
            f"--rpc-secret={self.rpc_secret}",
            "--rpc-allow-origin-all=true",
            "--max-connection-per-server=4",
            "--min-split-size=1M",
            "--continue=true",
            "--max-tries=5",
            "--retry-wait=10",
            "--auto-file-renaming=false",
            "--console-log-level=warn",
        ]
        try:
            return subprocess.Popen(
                args,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )
        except OSError as exc:
            raise EnvironmentError(f"å¯åŠ¨ aria2c å¤±è´¥: {exc}") from exc

    def _ensure_daemon_ready(self, timeout=10.0):
        start = time.time()
        last_error = None
        while time.time() - start < timeout:
            if self._aria2_process.poll() is not None:
                raise EnvironmentError("aria2c è¿›ç¨‹æå‰é€€å‡ºï¼Œè¯·æ£€æŸ¥å®‰è£…å’Œé…ç½®")
            try:
                with self._api_lock:
                    self._client.get_version()
                return
            except Exception as exc:
                last_error = exc
                time.sleep(0.2)
        raise EnvironmentError(f"aria2c RPC æœªå°±ç»ª: {last_error}")

    def shutdown(self):
        process = getattr(self, "_aria2_process", None)
        if not process:
            return
        if process.poll() is None:
            try:
                with self._api_lock:
                    try:
                        downloads = self._api.get_downloads()
                        for download in downloads:
                            if download.status in ("active", "waiting", "paused"):
                                self._api.remove(download, force=True, files=False)
                    except Exception:
                        pass
                    try:
                        self._api.force_shutdown()
                    except Exception:
                        self._api.shutdown()
            except Exception:
                pass
            try:
                process.terminate()
            except Exception:
                pass
            try:
                process.wait(timeout=3)
            except Exception:
                try:
                    process.kill()
                except Exception:
                    pass
        self._aria2_process = None

    def download_file(self, url, local_path, resume=True):
        local_path = Path(local_path)
        local_path.parent.mkdir(parents=True, exist_ok=True)

        control_file = Path(str(local_path) + ".aria2")
        fresh_download = not resume or (
            local_path.exists() and not control_file.exists()
        )

        if fresh_download and local_path.exists():
            tqdm.write(f"â™»ï¸  è¦†ç›–ç°æœ‰æ–‡ä»¶: {local_path.name}")
            try:
                local_path.unlink()
            except OSError as exc:
                tqdm.write(f"âš ï¸  æ— æ³•åˆ é™¤æ—§æ–‡ä»¶ {local_path.name}: {exc}")
                return DownloadResult(success=False, message=str(exc))

        if fresh_download and control_file.exists():
            try:
                control_file.unlink()
            except OSError:
                pass

        if self._aria2_process.poll() is not None:
            raise EnvironmentError("aria2c è¿›ç¨‹ä¸å¯ç”¨ï¼Œè¯·é‡è¯•æˆ–æ£€æŸ¥å®‰è£…")

        headers = [f"{key}: {value}" for key, value in self.default_headers.items()]
        options = {
            "dir": str(local_path.parent),
            "out": local_path.name,
            "continue": "true",
            "allow-overwrite": "true" if fresh_download else "false",
            "auto-file-renaming": "false",
            "max-connection-per-server": "8",
            "min-split-size": "1M",
            "max-tries": "5",
            "retry-wait": "10",
            "header": headers,
        }

        user_agent = self.default_headers.get("user-agent")
        if user_agent:
            options["user-agent"] = user_agent

        position = _aria2_acquire_position()
        progress_bar = tqdm(
            total=1,
            desc=local_path.name,
            unit="B",
            unit_scale=True,
            unit_divisor=1024,
            leave=False,
            position=position,
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]",
        )

        download = None
        try:
            try:
                with self._api_lock:
                    download = self._api.add_uris([url], options=options)
            except Exception as exc:
                tqdm.write(f"âŒ å¯åŠ¨ aria2 ä»»åŠ¡å¤±è´¥: {local_path.name} | {exc}")
                return DownloadResult(success=False, message=str(exc))

            while True:
                if interrupted:
                    try:
                        with self._api_lock:
                            if download is not None:
                                self._api.pause(download.gid)
                    except Exception:
                        pass
                    tqdm.write(f"â¹ï¸  æ‰‹åŠ¨ä¸­æ–­ aria2 ä»»åŠ¡: {local_path.name}")
                    return DownloadResult(success=False, message="interrupted")

                try:
                    with self._api_lock:
                        current_download = self._api.get_download(download.gid)
                except Exception as exc:
                    tqdm.write(f"âŒ æ— æ³•è·å– aria2 çŠ¶æ€: {local_path.name} | {exc}")
                    return DownloadResult(success=False, message=str(exc))

                total = int(current_download.total_length or 0)
                completed = int(current_download.completed_length or 0)
                speed = int(current_download.download_speed or 0)
                connections = current_download.connections or 0

                if total > 0 and progress_bar.total != total:
                    progress_bar.total = total

                delta = completed - progress_bar.n
                if delta < 0:
                    progress_bar.reset(total=progress_bar.total)
                    progress_bar.update(completed)
                elif delta:
                    progress_bar.update(delta)

                eta_str = self._format_eta(total, completed, speed)
                progress_bar.set_postfix_str(
                    f"CN:{connections} DL:{self._format_speed(speed)} ETA:{eta_str}"
                )
                progress_bar.refresh()

                status = current_download.status
                if status == "complete":
                    return DownloadResult(success=True)
                if status == "error":
                    status_code = self._parse_http_status(
                        current_download.error_message
                    )
                    message = (
                        current_download.error_message
                        or f"aria2 é”™è¯¯ç  {current_download.error_code}"
                    )
                    tqdm.write(f"âŒ aria2 ä¸‹è½½å¤±è´¥: {local_path.name} | {message}")
                    return DownloadResult(
                        success=False, status_code=status_code, message=message
                    )
                if status == "removed":
                    tqdm.write(f"âŒ aria2 ä»»åŠ¡è¢«ç§»é™¤: {local_path.name}")
                    return DownloadResult(success=False, message="removed")

                time.sleep(0.3)
        finally:
            progress_bar.close()
            _aria2_release_position(position)
            if download is not None:
                try:
                    with self._api_lock:
                        self._api.remove_download_result(download)
                except Exception:
                    pass


class HFDownloader:
    def __init__(
        self,
        lfs_base_url="https://xget.xi-xu.me/hf",
        hf_base_url="https://hf-mirror.com",
        downloader_type="requests",
    ):
        self.lfs_base_url = lfs_base_url
        self.hf_base_url = hf_base_url
        self.hf_api = HfApi(endpoint=hf_base_url)

        # LFS æ–‡ä»¶å¤§å°é˜ˆå€¼ (50MB)
        self.lfs_size_threshold = 50 * 1024 * 1024

        # ç¼“å­˜å½“å‰è§£æåˆ°çš„æäº¤å“ˆå¸Œï¼Œä¾›å†™å…¥å…ƒæ•°æ®ä½¿ç”¨
        self.resolved_commit_hash = None

        # é€‰æ‹©ä¸‹è½½å™¨
        self.downloader: DownloaderInterface = None
        if downloader_type == "requests":
            self.downloader = RequestsDownloader()
        elif downloader_type == "aria2":
            self.downloader = Aria2Downloader()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¸‹è½½å™¨ç±»å‹: {downloader_type}")

        print(f"ğŸ› ï¸  ä¸‹è½½æ ¸å¿ƒ: {self.downloader.get_name()}")
        print(f"ğŸª  HF é•œåƒ: {self.hf_base_url}")
        print(f"ğŸš€  LFS åŠ é€Ÿ: {self.lfs_base_url}")

    def get_repo_file_list(self, repo_id, repo_type="model", revision="main"):
        """è·å–ä»“åº“æ–‡ä»¶åˆ—è¡¨å’Œè¯¦ç»†ä¿¡æ¯"""
        try:
            print(f"ğŸ“¡ è·å–æ–‡ä»¶åˆ—è¡¨: {repo_type} {repo_id} @ {revision}")

            repo_info = self.hf_api.repo_info(
                repo_id, repo_type=repo_type, revision=revision, files_metadata=True
            )

            self.resolved_commit_hash = (
                getattr(repo_info, "sha", None)
                or getattr(repo_info, "commit", None)
                or getattr(repo_info, "commit_hash", None)
            )

            files_info = []
            for sibling in repo_info.siblings:
                file_info = {
                    "filename": sibling.rfilename,
                    "size": sibling.size,
                    "lfs": sibling.lfs,
                    "blob_id": sibling.blob_id,
                }
                files_info.append(file_info)

            return files_info

        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯401é”™è¯¯ï¼Œå¦‚æœæ˜¯åˆ™ä¸é‡è¯•
            if (
                hasattr(e, "response")
                and e.response is not None
                and e.response.status_code == 401
            ):
                print(f"ğŸš« è®¿é—®å—é™ (401): {repo_id} | {e}")
                return []
            print(f"âŒ è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def is_lfs_file(self, file_info):
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸º LFS æ–‡ä»¶"""
        return file_info.get("lfs") is not None

    def build_download_url(
        self, repo_id, filename, repo_type="model", revision="main", is_lfs=False
    ):
        """æ„å»ºä¸‹è½½ URL"""
        # ç¡®ä¿æ–‡ä»¶ååœ¨URLä¸­ä½¿ç”¨æ­£æ–œæ 
        url_filename = filename.replace("\\", "/")

        if is_lfs:
            # LFS æ–‡ä»¶ä½¿ç”¨ LFS åœ°å€
            if repo_type == "dataset":
                hf_url = f"https://huggingface.co/datasets/{repo_id}/resolve/{revision}/{url_filename}?download=true"
            elif repo_type == "space":
                hf_url = f"https://huggingface.co/spaces/{repo_id}/resolve/{revision}/{url_filename}?download=true"
            else:  # model
                hf_url = f"https://huggingface.co/{repo_id}/resolve/{revision}/{url_filename}?download=true"

            download_url = hf_url.replace("https://huggingface.co", self.lfs_base_url)
            url_type = "LFS"
        else:
            # æ™®é€šæ–‡ä»¶ä½¿ç”¨ hf-mirror
            # download_url = None
            download_url = hf_hub_url(
                repo_id,
                filename,
                repo_type=repo_type,
                revision=revision,
                endpoint=self.hf_base_url,
            )
            url_type = "HF"

        hf_mirror_param = {
            "repo_id": repo_id,
            "filename": filename,
            "revision": revision,
            "repo_type": repo_type,
        }

        return download_url, url_type, hf_mirror_param

    def _extract_expected_etag(self, file_info):
        """ä»æ–‡ä»¶ä¿¡æ¯ä¸­è§£ææœŸæœ›çš„ ETagã€‚"""

        lfs_info = file_info.get("lfs")
        if lfs_info is not None:
            sha256 = getattr(lfs_info, "sha256", None)
            if sha256 is None and isinstance(lfs_info, dict):
                sha256 = lfs_info.get("sha256")
            if sha256:
                return sha256

            oid = getattr(lfs_info, "oid", None)
            if oid is None and isinstance(lfs_info, dict):
                oid = lfs_info.get("oid")
            if isinstance(oid, str) and oid.startswith("sha256:"):
                return oid.split(":", 1)[1]
            return oid

        return file_info.get("blob_id")

    def verify_file_integrity(
        self, local_dir, file_path: Path, file_info, force_regenerate_etag=False
    ):
        """é€šè¿‡å…ƒæ•°æ®éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ã€‚"""

        if not file_path.exists():
            return False

        expected_size = file_info.get("size")
        if expected_size is not None:
            actual_size = file_path.stat().st_size
            if actual_size != expected_size:
                print(
                    f"âŒ æ–‡ä»¶å¤§å°ä¸åŒ¹é…: {file_path.name} | æœŸæœ› {expected_size}, å®é™… {actual_size}"
                )
                return False

        metadata = None
        filename = file_info.get("filename")

        if force_regenerate_etag:
            self._write_local_metadata(local_dir, file_info)

        try:
            metadata = hf_read_download_metadata(Path(local_dir), filename)
        except Exception as e:
            print(f"âš ï¸  è¯»å–å…ƒæ•°æ®å¤±è´¥ {file_path.name}: {e}")

        if metadata is None:
            self._write_local_metadata(local_dir, file_info)
            try:
                metadata = hf_read_download_metadata(Path(local_dir), filename)
            except Exception as e:
                print(f"âš ï¸  è¯»å–å…ƒæ•°æ®å¤±è´¥ {file_path.name}: {e}")

        if metadata is None:
            print(f"âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆå…ƒæ•°æ® {file_path.name}")
            return False

        expected_etag = self._extract_expected_etag(file_info)
        if expected_etag and metadata.etag != expected_etag:
            print(
                f"âŒ ETag ä¸åŒ¹é…: {file_path.name} | æœŸæœ› {expected_etag}, å®é™… {metadata.etag}"
            )
            return False

        if (
            self.resolved_commit_hash
            and metadata.commit_hash
            and metadata.commit_hash != self.resolved_commit_hash
        ):
            print(
                f"âŒ æäº¤å“ˆå¸Œä¸åŒ¹é…: {file_path.name} | å½“å‰ {self.resolved_commit_hash}, å…ƒæ•°æ® {metadata.commit_hash}"
            )
            return False

        return True

    def _write_local_metadata(self, local_dir, file_info):
        """å°†ä¸‹è½½çš„æ–‡ä»¶å…ƒæ•°æ®å†™å…¥æœ¬åœ°ç¼“å­˜ç›®å½•ã€‚"""

        filename = file_info.get("filename")
        if self.is_lfs_file(file_info):
            with open(Path(local_dir) / filename, "rb") as f:
                etag = sha_fileobj(f).hex()
        else:
            with open(Path(local_dir) / filename, "rb") as f:
                etag = git_hash(f.read())

        try:
            hf_write_download_metadata(
                Path(local_dir), filename, self.resolved_commit_hash, etag
            )
        except Exception as e:
            print(f"âš ï¸  å†™å…¥å…ƒæ•°æ®å¤±è´¥ {file_info['filename']}: {e}")

    def download_and_verify_file(
        self,
        url: str,
        local_dir: Path,
        local_path: Path,
        file_info,
        url_type,
        hf_mirror_param,
        max_attempts=5,
    ):
        """ä¸‹è½½æ–‡ä»¶å¹¶éªŒè¯å®Œæ•´æ€§"""

        attempt = 0

        download_success = False
        performed_download = False
        while True:
            if interrupted:
                print(f"â¹ï¸  ä¸‹è½½è¢«ä¸­æ–­ï¼Œè·³è¿‡: {local_path.name}")
                return {"success": False, "downloaded": False, "url_type": url_type}

            if self.verify_file_integrity(
                local_dir,
                local_path,
                file_info,
                force_regenerate_etag=performed_download,
            ):
                print(f"âœ… å·²å­˜åœ¨ä¸”é€šè¿‡æ ¡éªŒ: {local_path.name}")
                return {
                    "success": True,
                    "downloaded": performed_download,
                    "url_type": url_type,
                }

            if attempt >= max_attempts:
                # ä¸‹è½½å¤±è´¥
                print(f"ğŸš« è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒä¸‹è½½: {local_path.name}")
                return {"success": False, "downloaded": False, "url_type": url_type}

            attempt += 1
            attempt_note = f"{attempt}/{max_attempts}æ¬¡å°è¯•"
            print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½: {local_path.name} | æ¥æº: {url_type} | {attempt_note}")
            final_source = url_type

            if url_type in ["LFS"]:
                try:
                    download_result = self.downloader.download_file(url, local_path)
                    performed_download = True

                    if download_result.success:
                        download_success = True
                    else:
                        status_code = download_result.status_code
                        if status_code in {401, 403, 404}:
                            print(
                                f"ğŸ”€ LFS ä¸‹è½½é”™è¯¯ï¼š{status_code=}, å°è¯•åˆ‡æ¢ HF ä¸‹è½½: {local_path.name}"
                            )
                            local_path.unlink(missing_ok=True)
                            control_file = Path(str(local_path) + ".aria2")
                            control_file.unlink(missing_ok=True)
                            url_type = "HF"
                        else:
                            message = download_result.message
                            if message:
                                print(
                                    f"âš ï¸ LFS ä¸‹è½½æœªå®Œæˆ: {local_path.name} | {message}"
                                )
                            else:
                                print(f"âš ï¸ LFS ä¸‹è½½æœªå®Œæˆ: {local_path.name}")
                except Exception as e:
                    performed_download = True
                    print(f"âŒ LFS ä¸‹è½½å¼‚å¸¸: {local_path.name} | {e}")
                    print(traceback.format_exc())
            elif url_type in ["HF"]:
                try:
                    self.hf_api.hf_hub_download(
                        **hf_mirror_param, local_dir=local_dir, resume_download=True
                    )
                    download_success = True
                    performed_download = True
                except Exception as e:
                    performed_download = True
                    if (
                        hasattr(e, "response")
                        and e.response is not None
                        and e.response.status_code in [401, 403, 404]
                    ):
                        print(
                            f"ğŸš« HF è®¿é—®å—é™ ({e.response.status_code}): {local_path.name} | {e}"
                        )
                        return {
                            "success": False,
                            "downloaded": performed_download,
                            "url_type": url_type,
                        }
                    print(f"âŒ HFä¸‹è½½å¼‚å¸¸: {local_path.name} | {e}")
            else:
                print(f"âŒ æœªçŸ¥ä¸‹è½½ç±»å‹: {url_type} | {local_path.name}")
                return {"success": False, "downloaded": False, "url_type": url_type}

            if not download_success:
                if attempt < max_attempts:
                    wait_seconds = 2
                    print(
                        f"ğŸ” å‡†å¤‡é‡è¯•: {local_path.name} | ä¸‹ä¸€æ¬¡å°è¯• {attempt + 1}/{max_attempts} | ç­‰å¾… {wait_seconds}s"
                    )
                    time.sleep(wait_seconds)
                    continue
                print(f"ğŸš« æ”¾å¼ƒä¸‹è½½: {local_path.name} | å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
                return {
                    "success": False,
                    "downloaded": performed_download,
                    "url_type": final_source,
                }

            if download_success:
                if local_path.exists():
                    size_mb = local_path.stat().st_size / (1024 * 1024)
                    print(f"âœ… ä¸‹è½½ç»“æŸ: {local_path.name} | {size_mb:.3f} MB")
                else:
                    print(f"âœ… ä¸‹è½½ç»“æŸ: {local_path.name}")

    def download_repo(
        self,
        repo_id,
        local_dir,
        repo_type="model",
        revision="main",
        max_workers=4,
        include_patterns=None,
        exclude_patterns=None,
    ):
        """ä¸‹è½½æ•´ä¸ªä»“åº“"""
        # éªŒè¯ä»“åº“ID
        print(f"ğŸ” éªŒè¯ä»“åº“: {repo_type} {repo_id} @ {revision}")
        try:
            self.hf_api.repo_info(repo_id, repo_type=repo_type, revision=revision)
        except Exception as e:
            print(f"âŒ ä»“åº“ä¿¡æ¯æ— æ•ˆ: {e}")
            return False

        local_dir = Path(local_dir)
        local_dir.mkdir(parents=True, exist_ok=True)

        # è·å–æ–‡ä»¶åˆ—è¡¨
        files_info = self.get_repo_file_list(repo_id, repo_type, revision)

        if not files_info:
            print("âŒ æœªæ‰¾åˆ°æ–‡ä»¶æˆ–æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨")
            return False

        # è¿‡æ»¤æ–‡ä»¶
        if include_patterns:
            files_info = [
                f
                for f in files_info
                if any(pattern in f["filename"] for pattern in include_patterns)
            ]

        if exclude_patterns:
            files_info = [
                f
                for f in files_info
                if not any(pattern in f["filename"] for pattern in exclude_patterns)
            ]

        # åˆ†ç±»æ–‡ä»¶
        lfs_files = []
        regular_files = []

        for file_info in files_info:
            if self.is_lfs_file(file_info):
                lfs_files.append(file_info)
            else:
                regular_files.append(file_info)

        total_files = len(files_info)
        print(
            f"ğŸ“‚ æ–‡ä»¶ç»Ÿè®¡: å…± {total_files} ä¸ª | LFS: {len(lfs_files)} | æ™®é€š (hf-mirror): {len(regular_files)}"
        )

        files_to_download = []

        for file_info in files_info:
            filename = file_info["filename"]
            local_path = local_dir / filename
            is_lfs = self.is_lfs_file(file_info)

            url, url_type, hf_mirror_param = self.build_download_url(
                repo_id, filename, repo_type, revision, is_lfs
            )
            source_icon = "ğŸ”—" if url_type == "LFS" else "ğŸª"
            print(f"{source_icon} æ’é˜Ÿ: {filename}")
            files_to_download.append(
                (url, local_path, file_info, url_type, hf_mirror_param)
            )

        print(f"\nğŸ§¾ ä»»åŠ¡æ€»æ•°: {len(files_to_download)}")

        if not files_to_download:
            print("âœ… æ‰€æœ‰æ–‡ä»¶å‡å·²é€šè¿‡æ ¡éªŒï¼Œæ— éœ€ä¸‹è½½")
            return True

        print("ğŸš€ å¯åŠ¨ä¸‹è½½ä»»åŠ¡")

        # å¹¶å‘ä¸‹è½½æ–‡ä»¶
        successful_downloads = 0
        failed_downloads = 0
        total_bytes_downloaded = 0
        start_time = time.time()
        lfs_downloads = 0
        hf_downloads = 0
        verified_without_downloads = 0

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_task = {
                executor.submit(
                    self.download_and_verify_file,
                    url,
                    local_dir,
                    local_path,
                    file_info,
                    url_type,
                    hf_mirror_param,
                ): (url, local_path, file_info, url_type, hf_mirror_param)
                for url, local_path, file_info, url_type, hf_mirror_param in files_to_download
            }

            with tqdm(
                total=len(files_to_download),
                desc="æ–‡ä»¶ä¸‹è½½è¿›åº¦",
                unit="æ–‡ä»¶",
                position=0,
            ) as main_pbar:
                for future in as_completed(future_to_task):
                    # æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
                    if interrupted:
                        print(f"\nâš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å–æ¶ˆå‰©ä½™ä¸‹è½½ä»»åŠ¡...")
                        # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                        for f in future_to_task:
                            f.cancel()
                        break

                    try:
                        url, local_path, file_info, url_type, hf_mirror_param = (
                            future_to_task[future]
                        )
                        result = future.result()
                        if isinstance(result, dict):
                            if result.get("success"):
                                successful_downloads += 1
                                if result.get("downloaded"):
                                    if result.get("url_type") == "LFS":
                                        lfs_downloads += 1
                                    else:
                                        hf_downloads += 1
                                    if local_path.exists():
                                        total_bytes_downloaded += (
                                            local_path.stat().st_size
                                        )
                                else:
                                    verified_without_downloads += 1
                            else:
                                failed_downloads += 1
                                print(f"âŒ ä»»åŠ¡å¤±è´¥: {file_info['filename']}")
                        elif result:
                            successful_downloads += 1
                            if url_type == "LFS":
                                lfs_downloads += 1
                            else:
                                hf_downloads += 1
                            if local_path.exists():
                                total_bytes_downloaded += local_path.stat().st_size
                        else:
                            failed_downloads += 1
                            print(f"âŒ ä»»åŠ¡å¤±è´¥: {file_info['filename']}")
                    except Exception as e:
                        print(f"ğŸ’¥ ä»»åŠ¡å¼‚å¸¸: {local_path.name} | {e}")
                        failed_downloads += 1
                    finally:
                        main_pbar.update(1)

                        elapsed_time = time.time() - start_time
                        if elapsed_time > 0:
                            avg_speed = total_bytes_downloaded / elapsed_time
                            main_pbar.set_postfix(
                                {
                                    "æˆåŠŸ": successful_downloads,
                                    "å¤±è´¥": failed_downloads,
                                    "å·²éªŒè¯": verified_without_downloads,
                                    "å¹³å‡é€Ÿåº¦": f"{avg_speed / (1024*1024):.1f} MB/s",
                                }
                            )

        end_time = time.time()
        total_time = end_time - start_time
        avg_speed = total_bytes_downloaded / total_time if total_time > 0 else 0

        print(f"\nğŸ“Š ä¸‹è½½ç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸ: {successful_downloads}")
        print(f"    ğŸ”„ å·²å­˜åœ¨éªŒè¯: {verified_without_downloads}")
        print(f"    ğŸ”— Xgetä¸‹è½½: {lfs_downloads}")
        print(f"    ğŸª é•œåƒä¸‹è½½: {hf_downloads}")
        print(f"  âŒ å¤±è´¥: {failed_downloads}")
        print(f"  ğŸ“ æ€»è®¡: {len(files_to_download)}")
        print(f"  ğŸ’¾ ä¸‹è½½é‡: {total_bytes_downloaded / (1024*1024*1024):.2f} GB")
        print(f"  â±ï¸  ç”¨æ—¶: {total_time:.1f} ç§’")
        print(f"  ğŸš€ å¹³å‡é€Ÿåº¦: {avg_speed / (1024*1024):.1f} MB/s")
        print(f"  ğŸ”§ ä¸‹è½½æ ¸å¿ƒ: {self.downloader.get_name()}")

        return failed_downloads == 0


def main():
    parser = argparse.ArgumentParser(
        description="Hugging Face ä¸‹è½½åŠ é€Ÿå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python hfxget.py download microsoft/DialoGPT-medium --local-dir ./model
  python hfxget.py download squad --repo-type dataset --local-dir ./data
  python hfxget.py download microsoft/DialoGPT-medium --max-workers 8 --downloader requests
  python hfxget.py download bigscience/bloom --downloader aria2

ä¸‹è½½ç­–ç•¥:
  1. ä½¿ç”¨ HF API è·å–å®Œæ•´æ–‡ä»¶åˆ—è¡¨å’Œä¿¡æ¯
  2. å°æ–‡ä»¶ä» hf-mirror.com å¿«é€Ÿä¸‹è½½
  3. LFS å¤§æ–‡ä»¶ä» Xget åŠ é€Ÿä¸‹è½½
  4. éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ï¼ˆæ–‡ä»¶å¤§å°éªŒè¯ï¼‰
        """,
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    download_parser = subparsers.add_parser("download", help="ä¸‹è½½æ¨¡å‹/æ•°æ®é›†/ç©ºé—´")
    download_parser.add_argument("repo_id", help="ä»“åº“IDï¼Œæ ¼å¼: username/repo-name")
    download_parser.add_argument("--local-dir", required=True, help="æœ¬åœ°ç›®å½•è·¯å¾„")
    download_parser.add_argument(
        "--repo-type",
        choices=["model", "dataset", "space"],
        default="model",
        help="ä»“åº“ç±»å‹ (é»˜è®¤: model)",
    )
    download_parser.add_argument(
        "--revision", default="main", help="åˆ†æ”¯/æ ‡ç­¾/æäº¤ (é»˜è®¤: main)"
    )
    download_parser.add_argument(
        "--max-workers", type=int, default=4, help="å¹¶å‘ä¸‹è½½æ•° (é»˜è®¤: 4)"
    )
    download_parser.add_argument("--include", nargs="*", help="åŒ…å«çš„æ–‡ä»¶æ¨¡å¼")
    download_parser.add_argument("--exclude", nargs="*", help="æ’é™¤çš„æ–‡ä»¶æ¨¡å¼")
    download_parser.add_argument(
        "--hf-url",
        default="https://xget.xi-xu.me/hf",
        # default="https://hf-mirror.com",
        help="HF é•œåƒURLï¼Œç”¨äºæ™®é€šæ–‡ä»¶ (é»˜è®¤: https://hf-mirror.com)",
    )
    download_parser.add_argument(
        "--lfs-url",
        default="https://xget.xi-xu.me/hf",
        help="Xget åŸºç¡€URLï¼Œç”¨äº LFS æ–‡ä»¶ (é»˜è®¤: https://xget.xi-xu.me/hf)",
    )
    download_parser.add_argument(
        "--downloader",
        choices=["requests", "aria2"],
        default="requests",
        help="ä¸‹è½½æ ¸å¿ƒ",
    )

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    if args.command == "download":
        # æ£€æŸ¥ä¸‹è½½å™¨å¯ç”¨æ€§
        if args.downloader == "aria2" and not ARIA2P_AVAILABLE:
            print("âŒ aria2p åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install aria2p")
            return 1

        try:
            downloader = HFDownloader(
                args.lfs_url, args.hf_url, args.downloader
            )
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–ä¸‹è½½å™¨å¤±è´¥: {e}")
            return 1

        success = downloader.download_repo(
            repo_id=args.repo_id,
            local_dir=args.local_dir,
            repo_type=args.repo_type,
            revision=args.revision,
            max_workers=args.max_workers,
            include_patterns=args.include,
            exclude_patterns=args.exclude,
        )

        # æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
        if interrupted:
            print(f"\nâš ï¸  ä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­ (Ctrl+C)")
            print("å·²ä¸‹è½½çš„æ–‡ä»¶å°†ä¿ç•™åœ¨æœ¬åœ°ç›®å½•ä¸­")
            return 130  # æ ‡å‡†çš„ä¸­æ–­é€€å‡ºç 

        return 0 if success else 1

    return 1


if __name__ == "__main__":
    sys.exit(main())
