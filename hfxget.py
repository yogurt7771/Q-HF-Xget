#!/usr/bin/env python3
"""
Xget Hugging Face ä¸‹è½½åŠ é€Ÿå™¨
ç”¨äºæ›¿ä»£ hf download å‘½ä»¤ï¼Œé€šè¿‡ Xget åŠ é€Ÿä¸‹è½½ï¼Œé¿å…ç½‘ç»œé—®é¢˜

ç­–ç•¥ï¼š
1. ä½¿ç”¨ HF API è·å–å®Œæ•´æ–‡ä»¶åˆ—è¡¨
2. å°æ–‡ä»¶ä» hf-mirror.com ä¸‹è½½
3. LFS æ–‡ä»¶ä» Xget ä¸‹è½½
4. éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
"""

import argparse
import hashlib
import sys
import time
import traceback
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

try:
    import requests
    import urllib3
    from requests.adapters import HTTPAdapter
    from urllib3.util.retry import Retry

    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

from huggingface_hub import HfApi
from tqdm import tqdm


class DownloaderInterface(ABC):
    """ä¸‹è½½å™¨æŠ½è±¡æ¥å£"""

    @abstractmethod
    def download_file(self, url, local_path, resume=True, max_retries=3):
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        pass

    @abstractmethod
    def get_name(self):
        """è·å–ä¸‹è½½å™¨åç§°"""
        pass


class RequestsDownloader(DownloaderInterface):
    """åŸºäº requests åº“çš„ä¸‹è½½å™¨"""

    def get_name(self):
        return "requests"

    def download_file(self, url, local_path, resume=True, max_retries=3):
        """ä½¿ç”¨ requests ä¸‹è½½æ–‡ä»¶"""
        if not REQUESTS_AVAILABLE:
            raise ImportError("requests åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install requests")

        local_path = Path(local_path)
        local_path.parent.mkdir(parents=True, exist_ok=True)

        # å¦‚æœä¸ä½¿ç”¨æ–­ç‚¹ç»­ä¼ ï¼Œç›´æ¥ä¸‹è½½åˆ°ç›®æ ‡ä½ç½®
        if not resume:
            temp_path = local_path
            if local_path.exists():
                print(f"è¦†ç›–ç°æœ‰æ–‡ä»¶: {local_path.name}")
        else:
            # ä½¿ç”¨ .incomplete åç¼€çš„ä¸´æ—¶æ–‡ä»¶
            temp_path = local_path.with_suffix(local_path.suffix + ".incomplete")
            if local_path.exists():
                print(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {local_path.name}")
                return True

        # é…ç½®è¯·æ±‚ä¼šè¯
        session = requests.Session()
        session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Accept": "*/*",
                "Accept-Language": "en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7",
                "Accept-Encoding": "gzip, deflate, br",
                "Connection": "keep-alive",
            }
        )

        # ç¦ç”¨SSLè­¦å‘Š
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=max_retries,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"],
        )

        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        for attempt in range(max_retries + 1):
            headers = session.headers.copy()
            mode = "wb"
            initial_pos = 0

            # æ£€æŸ¥æ–­ç‚¹ç»­ä¼ 
            if resume and temp_path.exists() and temp_path != local_path:
                initial_pos = temp_path.stat().st_size
                headers["Range"] = f"bytes={initial_pos}-"
                mode = "ab"
                print(
                    f"æ–­ç‚¹ç»­ä¼ : {local_path.name} (ä» {initial_pos / (1024*1024):.1f} MB å¼€å§‹)"
                )

            try:
                response = session.get(
                    url,
                    headers=headers,
                    stream=True,
                    timeout=(30, 60),
                    verify=True,
                    allow_redirects=True,
                )

                if response.status_code == 416 and resume:
                    if temp_path.exists() and temp_path != local_path:
                        temp_path.rename(local_path)
                        print(f"æ–‡ä»¶å·²å®Œæ•´ï¼Œé‡å‘½å: {local_path.name}")
                        return True
                    return True

                response.raise_for_status()
                total_size = (
                    int(response.headers.get("content-length", 0)) + initial_pos
                )

                with open(temp_path, mode) as f:
                    with tqdm(
                        desc=local_path.name,
                        total=total_size,
                        initial=initial_pos,
                        unit="B",
                        unit_scale=True,
                        unit_divisor=1024,
                        leave=False,
                        bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]",
                    ) as pbar:
                        for chunk in response.iter_content(chunk_size=65536):
                            if chunk:
                                f.write(chunk)
                                pbar.update(len(chunk))

                # é‡å‘½åä¸´æ—¶æ–‡ä»¶
                if resume and temp_path != local_path:
                    temp_path.rename(local_path)

                return True

            except Exception as e:
                if attempt < max_retries:
                    print(
                        f"ä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {local_path.name}"
                    )
                    print(f"é”™è¯¯: {str(e)}")
                    time.sleep(2**attempt)
                    continue
                else:
                    print(f"ä¸‹è½½ {local_path.name} å¤±è´¥: {str(e)}")
                    if resume and temp_path.exists() and temp_path != local_path:
                        try:
                            temp_path.unlink()
                        except OSError:
                            pass
                    return False

        return False


class XgetHFDownloader:
    def __init__(
        self,
        xget_base_url="https://xget.xi-xu.me/hf",
        hf_mirror_url="https://hf-mirror.com",
        downloader_type="requests",
    ):
        self.xget_base_url = xget_base_url
        self.hf_mirror_url = hf_mirror_url
        self.hf_api = HfApi(endpoint=hf_mirror_url)

        # LFS æ–‡ä»¶å¤§å°é˜ˆå€¼ (100MB)
        self.lfs_size_threshold = 100 * 1024 * 1024

        # é€‰æ‹©ä¸‹è½½å™¨
        if downloader_type == "requests":
            self.downloader = RequestsDownloader()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¸‹è½½å™¨ç±»å‹: {downloader_type}")

        print(f"ä½¿ç”¨ä¸‹è½½æ ¸å¿ƒ: {self.downloader.get_name()}")
        print(f"HF é•œåƒ: {self.hf_mirror_url}")
        print(f"Xget åŠ é€Ÿ: {self.xget_base_url}")

    def get_repo_file_list(
        self, repo_id, repo_type="model", revision="main"
    ):
        """è·å–ä»“åº“æ–‡ä»¶åˆ—è¡¨å’Œè¯¦ç»†ä¿¡æ¯"""
        try:
            print(f"æ­£åœ¨è·å– {repo_type} {repo_id} çš„æ–‡ä»¶åˆ—è¡¨...")

            repo_info = self.hf_api.repo_info(repo_id, repo_type=repo_type, revision=revision, files_metadata=True)

            files_info = []
            for sibling in repo_info.siblings:
                file_info = {
                    "filename": sibling.rfilename,
                    "size": sibling.size,
                    "lfs": sibling.lfs,
                    "blob_id": sibling.blob_id,
                }
                files_info.append(file_info)

            return files_info

        except Exception as e:
            print(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def is_lfs_file(self, file_info):
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸º LFS æ–‡ä»¶"""
        # å¦‚æœ API ç›´æ¥æ ‡è®°äº† LFS
        print(file_info)
        if file_info.get("lfs"):
            return True

        return False

    def build_download_url(
        self, repo_id, filename, repo_type="model", revision="main", is_lfs=False
    ):
        """æ„å»ºä¸‹è½½ URL"""
        # ç¡®ä¿æ–‡ä»¶ååœ¨URLä¸­ä½¿ç”¨æ­£æ–œæ 
        url_filename = filename.replace("\\", "/")

        if is_lfs:
            # LFS æ–‡ä»¶ä½¿ç”¨ Xget
            if repo_type == "dataset":
                hf_url = f"https://huggingface.co/datasets/{repo_id}/resolve/{revision}/{url_filename}?download=true"
            elif repo_type == "space":
                hf_url = f"https://huggingface.co/spaces/{repo_id}/resolve/{revision}/{url_filename}?download=true"
            else:  # model
                hf_url = f"https://huggingface.co/{repo_id}/resolve/{revision}/{url_filename}?download=true"

            download_url = hf_url.replace("https://huggingface.co", self.xget_base_url)
            url_type = "Xget"
        else:
            # æ™®é€šæ–‡ä»¶ä½¿ç”¨ hf-mirror
            download_url = None
            url_type = "hf-mirror"
        hf_mirror_param = {"repo_id": repo_id, "filename": filename, "revision": revision, "repo_type": repo_type}

        return download_url, url_type, hf_mirror_param

    def verify_file_integrity(
        self, file_path, expected_size=None, expected_sha256=None
    ):
        """éªŒè¯æ–‡ä»¶å®Œæ•´æ€§"""
        if not file_path.exists():
            return False

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        if expected_size is not None:
            actual_size = file_path.stat().st_size
            if actual_size != expected_size:
                print(
                    f"æ–‡ä»¶å¤§å°ä¸åŒ¹é… {file_path.name}: æœŸæœ› {expected_size}, å®é™… {actual_size}"
                )
                return False

        # å¯¹å°æ–‡ä»¶éªŒè¯ SHA256ï¼ˆå¦‚æœæä¾›äº†å“ˆå¸Œå€¼ï¼‰
        if expected_sha256 and expected_size and expected_size < 500 * 1024 * 1024:
            try:
                sha256_hash = hashlib.sha256()
                with open(file_path, "rb") as f:
                    for chunk in iter(lambda: f.read(8192), b""):
                        sha256_hash.update(chunk)

                actual_sha256 = sha256_hash.hexdigest()
                if actual_sha256 != expected_sha256:
                    print(
                        f"SHA256ä¸åŒ¹é… {file_path.name}: æœŸæœ› {expected_sha256}, å®é™… {actual_sha256}"
                    )
                    return False
            except Exception as e:
                print(f"SHA256éªŒè¯å¤±è´¥ {file_path.name}: {e}")
                return False

        return True

    def download_and_verify_file(self, url, local_dir, local_path, file_info, url_type, hf_mirror_param):
        """ä¸‹è½½æ–‡ä»¶å¹¶éªŒè¯å®Œæ•´æ€§"""
        print(f"æ­£åœ¨ä¸‹è½½: {local_path.name} (ä½¿ç”¨ {url_type})")

        if url_type == "Xget":
            try:
                success = self.downloader.download_file(url, local_path, resume=True)
                if not success:
                    print(f"Xget ä¸‹è½½å¤±è´¥: {local_path.name}")
            except Exception as e:
                print(f"Xget ä¸‹è½½å¤±è´¥: {local_path.name}ï¼Œ{e}\n{traceback.format_exc()}")
                success = False
            if success:
                # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
                expected_size = file_info.get("size")
                if expected_size and local_path.exists():
                    if not self.verify_file_integrity(local_path, expected_size):
                        print(f"ä¸‹è½½å®Œæˆä½†éªŒè¯å¤±è´¥ï¼Œåˆ é™¤æ–‡ä»¶: {local_path.name}")
                        try:
                            local_path.unlink()
                        except OSError:
                            pass
                        return False

                size_mb = (
                    (local_path.stat().st_size / (1024 * 1024)) if local_path.exists() else 0
                )
                print(f"âœ“ ä¸‹è½½æˆåŠŸ: {local_path.name} ({size_mb:.1f} MB)")
                return True
        try:
            self.hf_api.hf_hub_download(**hf_mirror_param, local_dir=local_dir, resume_download=True)
            return True
        except Exception as e:
            print(f"ä¸‹è½½å¤±è´¥: {local_path.name}ï¼Œ{e}\n{traceback.format_exc()}")
            return False

    def download_repo(
        self,
        repo_id,
        local_dir,
        repo_type="model",
        revision="main",
        max_workers=4,
        include_patterns=None,
        exclude_patterns=None,
    ):
        """ä¸‹è½½æ•´ä¸ªä»“åº“"""
        # éªŒè¯ä»“åº“ID
        try:
            self.hf_api.repo_info(repo_id, repo_type=repo_type, revision=revision)
        except Exception as e:
            print(f"æ— æ•ˆçš„ä»“åº“ID: {e}")
            return False

        local_dir = Path(local_dir)
        local_dir.mkdir(parents=True, exist_ok=True)

        # è·å–æ–‡ä»¶åˆ—è¡¨
        files_info = self.get_repo_file_list(repo_id, repo_type, revision)

        if not files_info:
            print("æœªæ‰¾åˆ°æ–‡ä»¶æˆ–è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥")
            return False

        # è¿‡æ»¤æ–‡ä»¶
        if include_patterns:
            files_info = [
                f
                for f in files_info
                if any(pattern in f["filename"] for pattern in include_patterns)
            ]

        if exclude_patterns:
            files_info = [
                f
                for f in files_info
                if not any(pattern in f["filename"] for pattern in exclude_patterns)
            ]

        # åˆ†ç±»æ–‡ä»¶
        lfs_files = []
        regular_files = []

        for file_info in files_info:
            if self.is_lfs_file(file_info):
                lfs_files.append(file_info)
            else:
                regular_files.append(file_info)

        print(f"æ‰¾åˆ° {len(files_info)} ä¸ªæ–‡ä»¶:")
        print(f"  ğŸ”— LFSæ–‡ä»¶ (Xget): {len(lfs_files)}")
        print(f"  ğŸ“„ æ™®é€šæ–‡ä»¶ (hf-mirror): {len(regular_files)}")

        # æ£€æŸ¥å“ªäº›æ–‡ä»¶éœ€è¦ä¸‹è½½
        files_to_download = []
        files_already_complete = 0

        for file_info in files_info:
            filename = file_info["filename"]
            local_path = local_dir / filename
            is_lfs = self.is_lfs_file(file_info)

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦éœ€è¦ä¸‹è½½
            needs_download = False
            reason = ""

            if not local_path.exists():
                needs_download = True
                reason = "æ–‡ä»¶ä¸å­˜åœ¨"
            else:
                # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
                expected_size = file_info.get("size")
                if expected_size and self.verify_file_integrity(
                    local_path, expected_size
                ):
                    print(
                        f"âœ“ æ–‡ä»¶å®Œæ•´: {filename} ({expected_size / (1024*1024):.1f} MB)"
                    )
                    files_already_complete += 1
                    continue
                else:
                    needs_download = True
                    reason = "æ–‡ä»¶ä¸å®Œæ•´æˆ–å¤§å°ä¸åŒ¹é…"

            if needs_download:
                url, url_type, hf_mirror_param = self.build_download_url(
                    repo_id, filename, repo_type, revision, is_lfs
                )
                print(f"â†’ éœ€è¦ä¸‹è½½: {filename} ({reason}) - ä½¿ç”¨ {url_type}")
                files_to_download.append((url, local_path, file_info, url_type, hf_mirror_param))

        print(f"\néœ€è¦ä¸‹è½½: {len(files_to_download)} ä¸ªæ–‡ä»¶")
        print(f"å·²å®Œæ•´: {files_already_complete} ä¸ªæ–‡ä»¶")

        if not files_to_download:
            print("æ‰€æœ‰æ–‡ä»¶å·²ä¸‹è½½å®Œæˆ")
            return True

        print(f"å¼€å§‹ä¸‹è½½ {len(files_to_download)} ä¸ªæ–‡ä»¶")

        # å¹¶å‘ä¸‹è½½æ–‡ä»¶
        successful_downloads = 0
        failed_downloads = 0
        total_bytes_downloaded = 0
        start_time = time.time()
        xget_downloads = 0
        mirror_downloads = 0

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_task = {
                executor.submit(
                    self.download_and_verify_file, url, local_dir, local_path, file_info, url_type, hf_mirror_param
                ): (url, local_path, file_info, url_type, hf_mirror_param)
                for url, local_path, file_info, url_type, hf_mirror_param in files_to_download
            }

            with tqdm(
                total=len(files_to_download),
                desc="æ–‡ä»¶ä¸‹è½½è¿›åº¦",
                unit="æ–‡ä»¶",
                position=0,
            ) as main_pbar:
                for future in as_completed(future_to_task):
                    url, local_path, file_info, url_type = future_to_task[future]
                    try:
                        success = future.result()
                        if success:
                            successful_downloads += 1
                            if url_type == "Xget":
                                xget_downloads += 1
                            else:
                                mirror_downloads += 1
                            if local_path.exists():
                                total_bytes_downloaded += local_path.stat().st_size
                        else:
                            failed_downloads += 1
                            print(f"å¤±è´¥: {file_info['filename']}")
                    except Exception as e:
                        print(f"ä¸‹è½½ä»»åŠ¡å¼‚å¸¸: {e}")
                        failed_downloads += 1
                    finally:
                        main_pbar.update(1)

                        elapsed_time = time.time() - start_time
                        if elapsed_time > 0:
                            avg_speed = total_bytes_downloaded / elapsed_time
                            main_pbar.set_postfix(
                                {
                                    "æˆåŠŸ": successful_downloads,
                                    "å¤±è´¥": failed_downloads,
                                    "å¹³å‡é€Ÿåº¦": f"{avg_speed / (1024*1024):.1f} MB/s",
                                }
                            )

        end_time = time.time()
        total_time = end_time - start_time
        avg_speed = total_bytes_downloaded / total_time if total_time > 0 else 0

        print(f"\nğŸ“Š ä¸‹è½½ç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸ: {successful_downloads}")
        print(f"    ğŸ”— Xgetä¸‹è½½: {xget_downloads}")
        print(f"    ğŸª é•œåƒä¸‹è½½: {mirror_downloads}")
        print(f"  âŒ å¤±è´¥: {failed_downloads}")
        print(f"  ğŸ“ æ€»è®¡: {len(files_to_download)}")
        print(f"  ğŸ’¾ ä¸‹è½½é‡: {total_bytes_downloaded / (1024*1024*1024):.2f} GB")
        print(f"  â±ï¸  ç”¨æ—¶: {total_time:.1f} ç§’")
        print(f"  ğŸš€ å¹³å‡é€Ÿåº¦: {avg_speed / (1024*1024):.1f} MB/s")
        print(f"  ğŸ”§ ä¸‹è½½æ ¸å¿ƒ: {self.downloader.get_name()}")

        return failed_downloads == 0


def main():
    parser = argparse.ArgumentParser(
        description="Xget Hugging Face ä¸‹è½½åŠ é€Ÿå™¨ï¼ˆæ— Gitä¾èµ–ç‰ˆæœ¬ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python xget_hf.py download microsoft/DialoGPT-medium --local-dir ./model
  python xget_hf.py download squad --repo-type dataset --local-dir ./data
  python xget_hf.py download microsoft/DialoGPT-medium --max-workers 8 --downloader requests

ä¸‹è½½ç­–ç•¥:
  1. ä½¿ç”¨ HF API è·å–å®Œæ•´æ–‡ä»¶åˆ—è¡¨å’Œä¿¡æ¯
  2. å°æ–‡ä»¶ä» hf-mirror.com å¿«é€Ÿä¸‹è½½
  3. LFS å¤§æ–‡ä»¶ä» Xget åŠ é€Ÿä¸‹è½½
  4. éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ï¼ˆæ–‡ä»¶å¤§å°éªŒè¯ï¼‰
        """,
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    download_parser = subparsers.add_parser("download", help="ä¸‹è½½æ¨¡å‹/æ•°æ®é›†/ç©ºé—´")
    download_parser.add_argument("repo_id", help="ä»“åº“IDï¼Œæ ¼å¼: username/repo-name")
    download_parser.add_argument("--local-dir", required=True, help="æœ¬åœ°ç›®å½•è·¯å¾„")
    download_parser.add_argument(
        "--repo-type",
        choices=["model", "dataset", "space"],
        default="model",
        help="ä»“åº“ç±»å‹ (é»˜è®¤: model)",
    )
    download_parser.add_argument(
        "--revision", default="main", help="åˆ†æ”¯/æ ‡ç­¾/æäº¤ (é»˜è®¤: main)"
    )
    download_parser.add_argument(
        "--max-workers", type=int, default=4, help="å¹¶å‘ä¸‹è½½æ•° (é»˜è®¤: 4)"
    )
    download_parser.add_argument("--include", nargs="*", help="åŒ…å«çš„æ–‡ä»¶æ¨¡å¼")
    download_parser.add_argument("--exclude", nargs="*", help="æ’é™¤çš„æ–‡ä»¶æ¨¡å¼")
    download_parser.add_argument(
        "--hf-mirror-url",
        default="https://hf-mirror.com",
        help="HF é•œåƒURLï¼Œç”¨äºæ™®é€šæ–‡ä»¶ (é»˜è®¤: https://hf-mirror.com)",
    )
    download_parser.add_argument(
        "--xget-url",
        default="https://xget.xi-xu.me/hf",
        help="Xget åŸºç¡€URLï¼Œç”¨äº LFS æ–‡ä»¶ (é»˜è®¤: https://xget.xi-xu.me/hf)",
    )
    download_parser.add_argument(
        "--downloader",
        choices=["requests"],
        default="requests",
        help="ä¸‹è½½æ ¸å¿ƒ",
    )

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    if args.command == "download":
        # æ£€æŸ¥ä¸‹è½½å™¨å¯ç”¨æ€§
        if args.downloader == "requests" and not REQUESTS_AVAILABLE:
            print("é”™è¯¯: requests åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install requests")
            return 1

        try:
            downloader = XgetHFDownloader(
                args.xget_url, args.hf_mirror_url, args.downloader
            )
        except Exception as e:
            print(f"åˆå§‹åŒ–ä¸‹è½½å™¨å¤±è´¥: {e}")
            return 1

        success = downloader.download_repo(
            repo_id=args.repo_id,
            local_dir=args.local_dir,
            repo_type=args.repo_type,
            revision=args.revision,
            max_workers=args.max_workers,
            include_patterns=args.include,
            exclude_patterns=args.exclude,
        )

        return 0 if success else 1

    return 1


if __name__ == "__main__":
    sys.exit(main())
